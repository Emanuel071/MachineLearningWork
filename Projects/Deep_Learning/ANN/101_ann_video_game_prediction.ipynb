{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'c:\\Users\\eacalder\\.conda\\envs\\dsi-dl-ANN-2\\python.exe' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -p c:\\Users\\eacalder\\.conda\\envs\\dsi-dl-ANN-2 ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "#########################################################################\n",
    "# Artificial Neural Network - Video Game Success Prediction\n",
    "#########################################################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'c:\\Users\\eacalder\\.conda\\envs\\dsi-dl-ANN-2\\python.exe' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -p c:\\Users\\eacalder\\.conda\\envs\\dsi-dl-ANN-2 ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "#########################################################################\n",
    "# Import Libraries\n",
    "#########################################################################\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense,Activation\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################################################\n",
    "# Import Data\n",
    "#########################################################################\n",
    "\n",
    "# import data\n",
    "data_for_model = pd.read_csv(\"data/ann-game-data.csv\")\n",
    "\n",
    "# drop any redundant columns\n",
    "data_for_model.drop(\"player_id\", axis = 1, inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################################################\n",
    "# Split Input Variables & Output Variable\n",
    "#########################################################################\n",
    "\n",
    "X = data_for_model.drop([\"success\"], axis = 1)\n",
    "y = data_for_model[\"success\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################################################\n",
    "# Split out Training & Test sets\n",
    "#########################################################################\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42, stratify = y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#########################################################################\n",
    "# Deal with Categorical Variables\n",
    "#########################################################################\n",
    "\n",
    "categorical_vars = [\"clan\"]\n",
    "\n",
    "one_hot_encoder = OneHotEncoder(sparse=False, drop = \"first\")\n",
    "\n",
    "X_train_encoded = one_hot_encoder.fit_transform(X_train[categorical_vars])\n",
    "X_test_encoded = one_hot_encoder.transform(X_test[categorical_vars])\n",
    "\n",
    "encoder_feature_names = one_hot_encoder.get_feature_names_out(categorical_vars)\n",
    "\n",
    "X_train_encoded = pd.DataFrame(X_train_encoded, columns = encoder_feature_names)\n",
    "X_train = pd.concat([X_train.reset_index(drop=True), X_train_encoded.reset_index(drop=True)], axis = 1)\n",
    "X_train.drop(categorical_vars, axis = 1, inplace = True)\n",
    "\n",
    "X_test_encoded = pd.DataFrame(X_test_encoded, columns = encoder_feature_names)\n",
    "X_test = pd.concat([X_test.reset_index(drop=True), X_test_encoded.reset_index(drop=True)], axis = 1)\n",
    "X_test.drop(categorical_vars, axis = 1, inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################################################\n",
    "# Feature Scaling\n",
    "#########################################################################\n",
    "\n",
    "scale_norm = MinMaxScaler()\n",
    "X_train = pd.DataFrame(scale_norm.fit_transform(X_train), columns = X_train.columns)\n",
    "X_test = pd.DataFrame(scale_norm.transform(X_test), columns = X_test.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################################################\n",
    "# Network Architecture\n",
    "#########################################################################\n",
    "\n",
    "# network architecture\n",
    "\n",
    "\n",
    "\n",
    "# compile network\n",
    "\n",
    "\n",
    "\n",
    "# view network architecture\n",
    "\n",
    "\n",
    "\n",
    "#########################################################################\n",
    "# Train Our Network!\n",
    "#########################################################################\n",
    "\n",
    "# training parameters\n",
    "\n",
    "\n",
    "\n",
    "# callbacks\n",
    "\n",
    "\n",
    "\n",
    "# train the network\n",
    "\n",
    "\n",
    "\n",
    "#########################################################################\n",
    "# Visualise Training & Validation Performance\n",
    "#########################################################################\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# plot metrics by epoch\n",
    "fig, ax = plt.subplots(2, 1, figsize=(15,15))\n",
    "ax[0].set_title('Loss')\n",
    "ax[0].plot(history.epoch, history.history[\"loss\"], label=\"Training Loss\")\n",
    "ax[0].plot(history.epoch, history.history[\"val_loss\"], label=\"Validation Loss\")\n",
    "ax[1].set_title('Accuracy')\n",
    "ax[1].plot(history.epoch, history.history[\"accuracy\"], label=\"Training Accuracy\")\n",
    "ax[1].plot(history.epoch, history.history[\"val_accuracy\"], label=\"Validation Accuracy\")\n",
    "ax[0].legend()\n",
    "ax[1].legend()\n",
    "plt.show()\n",
    "\n",
    "# get best epoch performance for validation accuracy\n",
    "max(history.history['val_accuracy'])\n",
    "\n",
    "\n",
    "#########################################################################\n",
    "# Make Predictions On New Data\n",
    "#########################################################################\n",
    "\n",
    "# import packages\n",
    "\n",
    "\n",
    "\n",
    "# load model\n",
    "\n",
    "\n",
    "\n",
    "# create new data\n",
    "\n",
    "\n",
    "\n",
    "# make our prediction\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
