{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a09aef32",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-06T15:33:07.654887Z",
     "iopub.status.busy": "2023-10-06T15:33:07.654209Z",
     "iopub.status.idle": "2023-10-06T15:33:56.241673Z",
     "shell.execute_reply": "2023-10-06T15:33:56.240192Z"
    },
    "papermill": {
     "duration": 48.596431,
     "end_time": "2023-10-06T15:33:56.244231",
     "exception": false,
     "start_time": "2023-10-06T15:33:07.647800",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyspark\r\n",
      "  Downloading pyspark-3.5.0.tar.gz (316.9 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m316.9/316.9 MB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l-\b \bdone\r\n",
      "\u001b[?25hRequirement already satisfied: py4j==0.10.9.7 in /opt/conda/lib/python3.10/site-packages (from pyspark) (0.10.9.7)\r\n",
      "Building wheels for collected packages: pyspark\r\n",
      "  Building wheel for pyspark (setup.py) ... \u001b[?25l-\b \b\\\b \b|\b \bdone\r\n",
      "\u001b[?25h  Created wheel for pyspark: filename=pyspark-3.5.0-py2.py3-none-any.whl size=317425350 sha256=2558db08aaaaef9da96a0baaec9031142f071048b1e504b0defdf8884a47c164\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/41/4e/10/c2cf2467f71c678cfc8a6b9ac9241e5e44a01940da8fbb17fc\r\n",
      "Successfully built pyspark\r\n",
      "Installing collected packages: pyspark\r\n",
      "Successfully installed pyspark-3.5.0\r\n"
     ]
    }
   ],
   "source": [
    "!pip install pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "91db5069",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-06T15:33:56.267263Z",
     "iopub.status.busy": "2023-10-06T15:33:56.266915Z",
     "iopub.status.idle": "2023-10-06T15:33:56.858830Z",
     "shell.execute_reply": "2023-10-06T15:33:56.857775Z"
    },
    "papermill": {
     "duration": 0.606289,
     "end_time": "2023-10-06T15:33:56.861203",
     "exception": false,
     "start_time": "2023-10-06T15:33:56.254914",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark import SparkConf, SparkContext\n",
    "from pyspark.sql import SparkSession, SQLContext\n",
    "\n",
    "from pyspark.sql.types import *\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.functions import udf, col\n",
    "\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.mllib.evaluation import RegressionMetrics\n",
    "\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator, CrossValidatorModel\n",
    "from pyspark.ml.feature import VectorAssembler, StandardScaler\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.feature import Tokenizer, HashingTF,IDF, Normalizer, VectorAssembler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2e4ea3f7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-06T15:33:56.884671Z",
     "iopub.status.busy": "2023-10-06T15:33:56.883518Z",
     "iopub.status.idle": "2023-10-06T15:34:03.574108Z",
     "shell.execute_reply": "2023-10-06T15:34:03.572714Z"
    },
    "papermill": {
     "duration": 6.704706,
     "end_time": "2023-10-06T15:34:03.576748",
     "exception": false,
     "start_time": "2023-10-06T15:33:56.872042",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "23/10/06 15:34:00 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://70c2c572bda3:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[2]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>testing-NLP</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x799db9e5bbb0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark = SparkSession.\\\n",
    "            builder.\\\n",
    "            master(\"local[2]\").\\\n",
    "            appName(\"testing-NLP\").getOrCreate()\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "24566df2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-06T15:34:03.618778Z",
     "iopub.status.busy": "2023-10-06T15:34:03.618070Z",
     "iopub.status.idle": "2023-10-06T15:34:03.630115Z",
     "shell.execute_reply": "2023-10-06T15:34:03.629391Z"
    },
    "papermill": {
     "duration": 0.036749,
     "end_time": "2023-10-06T15:34:03.632212",
     "exception": false,
     "start_time": "2023-10-06T15:34:03.595463",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://70c2c572bda3:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[2]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>testing-NLP</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=local[2] appName=testing-NLP>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc = spark.sparkContext\n",
    "sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "27c94a49",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-06T15:34:03.664939Z",
     "iopub.status.busy": "2023-10-06T15:34:03.664599Z",
     "iopub.status.idle": "2023-10-06T15:34:10.275761Z",
     "shell.execute_reply": "2023-10-06T15:34:10.274504Z"
    },
    "papermill": {
     "duration": 6.633952,
     "end_time": "2023-10-06T15:34:10.279365",
     "exception": false,
     "start_time": "2023-10-06T15:34:03.645413",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----------+\n",
      "|            sentence| word_array|\n",
      "+--------------------+-----------+\n",
      "|This is the first...|     [This]|\n",
      "|This is the first...|       [is]|\n",
      "|This is the first...|      [the]|\n",
      "|This is the first...|    [first]|\n",
      "|This is the first...|[sentence.]|\n",
      "|Here is the secon...|     [Here]|\n",
      "|Here is the secon...|       [is]|\n",
      "|Here is the secon...|      [the]|\n",
      "|Here is the secon...|   [second]|\n",
      "|Here is the secon...|[sentence.]|\n",
      "|And here's a thir...|      [And]|\n",
      "|And here's a thir...|   [here's]|\n",
      "|And here's a thir...|        [a]|\n",
      "|And here's a thir...|    [third]|\n",
      "|And here's a thir...|[sentence.]|\n",
      "+--------------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Sample sentences in a list\n",
    "sentences_list = [\n",
    "    \"This is the first sentence.\",\n",
    "    \"Here is the second sentence.\",\n",
    "    \"And here's a third sentence.\"\n",
    "]\n",
    "\n",
    "# Create a DataFrame with a column containing sentences\n",
    "df = spark.createDataFrame([(sentence,) for sentence in sentences_list], [\"sentence\"])\n",
    "\n",
    "# Split the sentences into words\n",
    "df = df.withColumn(\"words\", F.split(\"sentence\", \" \"))\n",
    "\n",
    "# Explode the words into separate rows\n",
    "df_words = df.withColumn(\"word\", F.explode(\"words\")).drop(\"words\")\n",
    "\n",
    "# Convert words into an array of strings (single word per array)\n",
    "df_words = df_words.withColumn(\"word_array\", F.array(\"word\")).drop(\"word\")\n",
    "\n",
    "df_words.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9aaa8235",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-06T15:34:10.320893Z",
     "iopub.status.busy": "2023-10-06T15:34:10.320136Z",
     "iopub.status.idle": "2023-10-06T15:34:13.268902Z",
     "shell.execute_reply": "2023-10-06T15:34:13.268033Z"
    },
    "papermill": {
     "duration": 2.971748,
     "end_time": "2023-10-06T15:34:13.271282",
     "exception": false,
     "start_time": "2023-10-06T15:34:10.299534",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----------+---------+\n",
      "|            sentence| word_array|wordCount|\n",
      "+--------------------+-----------+---------+\n",
      "|This is the first...|     [This]|        1|\n",
      "|This is the first...|       [is]|        1|\n",
      "|This is the first...|      [the]|        1|\n",
      "|This is the first...|    [first]|        1|\n",
      "|This is the first...|[sentence.]|        1|\n",
      "|Here is the secon...|     [Here]|        1|\n",
      "|Here is the secon...|       [is]|        1|\n",
      "|Here is the secon...|      [the]|        1|\n",
      "|Here is the secon...|   [second]|        1|\n",
      "|Here is the secon...|[sentence.]|        1|\n",
      "|And here's a thir...|      [And]|        1|\n",
      "|And here's a thir...|   [here's]|        1|\n",
      "|And here's a thir...|        [a]|        1|\n",
      "|And here's a thir...|    [third]|        1|\n",
      "|And here's a thir...|[sentence.]|        1|\n",
      "+--------------------+-----------+---------+\n",
      "\n",
      "root\n",
      " |-- sentence: string (nullable = true)\n",
      " |-- word_array: array (nullable = false)\n",
      " |    |-- element: string (containsNull = false)\n",
      " |-- wordCount: integer (nullable = false)\n",
      "\n",
      "None\n",
      "16\n",
      "+--------------------+-----------+---------------+\n",
      "|            sentence| word_array|    rawFeatures|\n",
      "+--------------------+-----------+---------------+\n",
      "|This is the first...|     [This]| (16,[3],[1.0])|\n",
      "|This is the first...|       [is]| (16,[9],[1.0])|\n",
      "|This is the first...|      [the]| (16,[1],[1.0])|\n",
      "|This is the first...|    [first]| (16,[3],[1.0])|\n",
      "|This is the first...|[sentence.]| (16,[8],[1.0])|\n",
      "|Here is the secon...|     [Here]|(16,[12],[1.0])|\n",
      "|Here is the secon...|       [is]| (16,[9],[1.0])|\n",
      "|Here is the secon...|      [the]| (16,[1],[1.0])|\n",
      "|Here is the secon...|   [second]| (16,[8],[1.0])|\n",
      "|Here is the secon...|[sentence.]| (16,[8],[1.0])|\n",
      "|And here's a thir...|      [And]| (16,[1],[1.0])|\n",
      "|And here's a thir...|   [here's]| (16,[0],[1.0])|\n",
      "|And here's a thir...|        [a]| (16,[3],[1.0])|\n",
      "|And here's a thir...|    [third]| (16,[3],[1.0])|\n",
      "|And here's a thir...|[sentence.]| (16,[8],[1.0])|\n",
      "+--------------------+-----------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# colecting word count for accurate modeling\n",
    "df_words = df_words.withColumn('wordCount', F.size(col('word_array')))\n",
    "df_words.show()\n",
    "print(df_words.printSchema()) \n",
    "# wordCount = df_words.select(sum('wordCount')).collect()\n",
    "wordCount = df_words.agg(F.sum(\"wordCount\").alias(\"sum_wordCount\")).collect()[0][\"sum_wordCount\"]\n",
    "# a power of 2 that is larger than your word count\n",
    "powerof2 = 2\n",
    "exponent = 1\n",
    "while wordCount > powerof2:\n",
    "    powerof2 = 2**exponent\n",
    "    exponent += 1\n",
    "print(powerof2)\n",
    "df_words = df_words.drop(\"wordCount\")\n",
    "# Compute Term Frequency (TF)\n",
    "hashingTF = HashingTF(inputCol=\"word_array\", outputCol=\"rawFeatures\", numFeatures=powerof2) \n",
    "df_words = hashingTF.transform(df_words)\n",
    "df_words.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6a6bc1c2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-06T15:34:13.295037Z",
     "iopub.status.busy": "2023-10-06T15:34:13.294668Z",
     "iopub.status.idle": "2023-10-06T15:34:17.024901Z",
     "shell.execute_reply": "2023-10-06T15:34:17.023129Z"
    },
    "papermill": {
     "duration": 3.744523,
     "end_time": "2023-10-06T15:34:17.027213",
     "exception": false,
     "start_time": "2023-10-06T15:34:13.282690",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checking IDF:\n",
      "+--------------------+-----------+---------------+--------------------+\n",
      "|            sentence| word_array|    rawFeatures|            features|\n",
      "+--------------------+-----------+---------------+--------------------+\n",
      "|This is the first...|     [This]| (16,[3],[1.0])|(16,[3],[1.163150...|\n",
      "|This is the first...|       [is]| (16,[9],[1.0])|(16,[9],[1.673976...|\n",
      "|This is the first...|      [the]| (16,[1],[1.0])|(16,[1],[1.386294...|\n",
      "|This is the first...|    [first]| (16,[3],[1.0])|(16,[3],[1.163150...|\n",
      "|This is the first...|[sentence.]| (16,[8],[1.0])|(16,[8],[1.163150...|\n",
      "|Here is the secon...|     [Here]|(16,[12],[1.0])|(16,[12],[2.07944...|\n",
      "|Here is the secon...|       [is]| (16,[9],[1.0])|(16,[9],[1.673976...|\n",
      "|Here is the secon...|      [the]| (16,[1],[1.0])|(16,[1],[1.386294...|\n",
      "|Here is the secon...|   [second]| (16,[8],[1.0])|(16,[8],[1.163150...|\n",
      "|Here is the secon...|[sentence.]| (16,[8],[1.0])|(16,[8],[1.163150...|\n",
      "|And here's a thir...|      [And]| (16,[1],[1.0])|(16,[1],[1.386294...|\n",
      "|And here's a thir...|   [here's]| (16,[0],[1.0])|(16,[0],[2.079441...|\n",
      "|And here's a thir...|        [a]| (16,[3],[1.0])|(16,[3],[1.163150...|\n",
      "|And here's a thir...|    [third]| (16,[3],[1.0])|(16,[3],[1.163150...|\n",
      "|And here's a thir...|[sentence.]| (16,[8],[1.0])|(16,[8],[1.163150...|\n",
      "+--------------------+-----------+---------------+--------------------+\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Compute Inverse Document Frequency (IDF) \n",
    "idf = IDF(inputCol=\"rawFeatures\", outputCol=\"features\") \n",
    "idfModel = idf.fit(df_words) \n",
    "df_words = idfModel.transform(df_words) \n",
    "print('checking IDF:')\n",
    "print(df_words.show())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3750de8c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-06T15:34:17.056528Z",
     "iopub.status.busy": "2023-10-06T15:34:17.056110Z",
     "iopub.status.idle": "2023-10-06T15:34:17.675829Z",
     "shell.execute_reply": "2023-10-06T15:34:17.674698Z"
    },
    "papermill": {
     "duration": 0.637253,
     "end_time": "2023-10-06T15:34:17.678675",
     "exception": false,
     "start_time": "2023-10-06T15:34:17.041422",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----------+---------------+--------------------+\n",
      "|            sentence| word_array|    rawFeatures|            features|\n",
      "+--------------------+-----------+---------------+--------------------+\n",
      "|This is the first...|     [This]| (16,[3],[1.0])|(16,[3],[1.163150...|\n",
      "|This is the first...|       [is]| (16,[9],[1.0])|(16,[9],[1.673976...|\n",
      "|This is the first...|      [the]| (16,[1],[1.0])|(16,[1],[1.386294...|\n",
      "|This is the first...|    [first]| (16,[3],[1.0])|(16,[3],[1.163150...|\n",
      "|This is the first...|[sentence.]| (16,[8],[1.0])|(16,[8],[1.163150...|\n",
      "|Here is the secon...|     [Here]|(16,[12],[1.0])|(16,[12],[2.07944...|\n",
      "|Here is the secon...|       [is]| (16,[9],[1.0])|(16,[9],[1.673976...|\n",
      "|Here is the secon...|      [the]| (16,[1],[1.0])|(16,[1],[1.386294...|\n",
      "|Here is the secon...|   [second]| (16,[8],[1.0])|(16,[8],[1.163150...|\n",
      "|Here is the secon...|[sentence.]| (16,[8],[1.0])|(16,[8],[1.163150...|\n",
      "|And here's a thir...|      [And]| (16,[1],[1.0])|(16,[1],[1.386294...|\n",
      "|And here's a thir...|   [here's]| (16,[0],[1.0])|(16,[0],[2.079441...|\n",
      "|And here's a thir...|        [a]| (16,[3],[1.0])|(16,[3],[1.163150...|\n",
      "|And here's a thir...|    [third]| (16,[3],[1.0])|(16,[3],[1.163150...|\n",
      "|And here's a thir...|[sentence.]| (16,[8],[1.0])|(16,[8],[1.163150...|\n",
      "+--------------------+-----------+---------------+--------------------+\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(df_words.show())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "819443a2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-06T15:34:17.720347Z",
     "iopub.status.busy": "2023-10-06T15:34:17.719451Z",
     "iopub.status.idle": "2023-10-06T15:34:18.373825Z",
     "shell.execute_reply": "2023-10-06T15:34:18.372548Z"
    },
    "papermill": {
     "duration": 0.678724,
     "end_time": "2023-10-06T15:34:18.376907",
     "exception": false,
     "start_time": "2023-10-06T15:34:17.698183",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----------+---------------+--------------------+---------------+\n",
      "|            sentence| word_array|    rawFeatures|            features|   normFeatures|\n",
      "+--------------------+-----------+---------------+--------------------+---------------+\n",
      "|This is the first...|     [This]| (16,[3],[1.0])|(16,[3],[1.163150...| (16,[3],[1.0])|\n",
      "|This is the first...|       [is]| (16,[9],[1.0])|(16,[9],[1.673976...| (16,[9],[1.0])|\n",
      "|This is the first...|      [the]| (16,[1],[1.0])|(16,[1],[1.386294...| (16,[1],[1.0])|\n",
      "|This is the first...|    [first]| (16,[3],[1.0])|(16,[3],[1.163150...| (16,[3],[1.0])|\n",
      "|This is the first...|[sentence.]| (16,[8],[1.0])|(16,[8],[1.163150...| (16,[8],[1.0])|\n",
      "|Here is the secon...|     [Here]|(16,[12],[1.0])|(16,[12],[2.07944...|(16,[12],[1.0])|\n",
      "|Here is the secon...|       [is]| (16,[9],[1.0])|(16,[9],[1.673976...| (16,[9],[1.0])|\n",
      "|Here is the secon...|      [the]| (16,[1],[1.0])|(16,[1],[1.386294...| (16,[1],[1.0])|\n",
      "|Here is the secon...|   [second]| (16,[8],[1.0])|(16,[8],[1.163150...| (16,[8],[1.0])|\n",
      "|Here is the secon...|[sentence.]| (16,[8],[1.0])|(16,[8],[1.163150...| (16,[8],[1.0])|\n",
      "|And here's a thir...|      [And]| (16,[1],[1.0])|(16,[1],[1.386294...| (16,[1],[1.0])|\n",
      "|And here's a thir...|   [here's]| (16,[0],[1.0])|(16,[0],[2.079441...| (16,[0],[1.0])|\n",
      "|And here's a thir...|        [a]| (16,[3],[1.0])|(16,[3],[1.163150...| (16,[3],[1.0])|\n",
      "|And here's a thir...|    [third]| (16,[3],[1.0])|(16,[3],[1.163150...| (16,[3],[1.0])|\n",
      "|And here's a thir...|[sentence.]| (16,[8],[1.0])|(16,[8],[1.163150...| (16,[8],[1.0])|\n",
      "+--------------------+-----------+---------------+--------------------+---------------+\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "normalizer = Normalizer(inputCol=\"features\", outputCol=\"normFeatures\")\n",
    "df_words_norm = normalizer.transform(df_words)\n",
    "print(df_words_norm.show())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "780a19b2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-06T15:34:18.407463Z",
     "iopub.status.busy": "2023-10-06T15:34:18.406951Z",
     "iopub.status.idle": "2023-10-06T15:34:21.046878Z",
     "shell.execute_reply": "2023-10-06T15:34:21.045800Z"
    },
    "papermill": {
     "duration": 2.65623,
     "end_time": "2023-10-06T15:34:21.050232",
     "exception": false,
     "start_time": "2023-10-06T15:34:18.394002",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----------+---------------+--------------------+---------------+--------------------+\n",
      "|            sentence| word_array|    rawFeatures|            features|   normFeatures|         tfidf_dense|\n",
      "+--------------------+-----------+---------------+--------------------+---------------+--------------------+\n",
      "|This is the first...|     [This]| (16,[3],[1.0])|(16,[3],[1.163150...| (16,[3],[1.0])|[0.0, 0.0, 0.0, 1...|\n",
      "|This is the first...|       [is]| (16,[9],[1.0])|(16,[9],[1.673976...| (16,[9],[1.0])|[0.0, 0.0, 0.0, 0...|\n",
      "|This is the first...|      [the]| (16,[1],[1.0])|(16,[1],[1.386294...| (16,[1],[1.0])|[0.0, 1.0, 0.0, 0...|\n",
      "|This is the first...|    [first]| (16,[3],[1.0])|(16,[3],[1.163150...| (16,[3],[1.0])|[0.0, 0.0, 0.0, 1...|\n",
      "|This is the first...|[sentence.]| (16,[8],[1.0])|(16,[8],[1.163150...| (16,[8],[1.0])|[0.0, 0.0, 0.0, 0...|\n",
      "|Here is the secon...|     [Here]|(16,[12],[1.0])|(16,[12],[2.07944...|(16,[12],[1.0])|[0.0, 0.0, 0.0, 0...|\n",
      "|Here is the secon...|       [is]| (16,[9],[1.0])|(16,[9],[1.673976...| (16,[9],[1.0])|[0.0, 0.0, 0.0, 0...|\n",
      "|Here is the secon...|      [the]| (16,[1],[1.0])|(16,[1],[1.386294...| (16,[1],[1.0])|[0.0, 1.0, 0.0, 0...|\n",
      "|Here is the secon...|   [second]| (16,[8],[1.0])|(16,[8],[1.163150...| (16,[8],[1.0])|[0.0, 0.0, 0.0, 0...|\n",
      "|Here is the secon...|[sentence.]| (16,[8],[1.0])|(16,[8],[1.163150...| (16,[8],[1.0])|[0.0, 0.0, 0.0, 0...|\n",
      "|And here's a thir...|      [And]| (16,[1],[1.0])|(16,[1],[1.386294...| (16,[1],[1.0])|[0.0, 1.0, 0.0, 0...|\n",
      "|And here's a thir...|   [here's]| (16,[0],[1.0])|(16,[0],[2.079441...| (16,[0],[1.0])|[1.0, 0.0, 0.0, 0...|\n",
      "|And here's a thir...|        [a]| (16,[3],[1.0])|(16,[3],[1.163150...| (16,[3],[1.0])|[0.0, 0.0, 0.0, 1...|\n",
      "|And here's a thir...|    [third]| (16,[3],[1.0])|(16,[3],[1.163150...| (16,[3],[1.0])|[0.0, 0.0, 0.0, 1...|\n",
      "|And here's a thir...|[sentence.]| (16,[8],[1.0])|(16,[8],[1.163150...| (16,[8],[1.0])|[0.0, 0.0, 0.0, 0...|\n",
      "+--------------------+-----------+---------------+--------------------+---------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Function to convert sparse vector to dense vector\n",
    "def sparse_to_dense(vector):\n",
    "    return vector.toArray().tolist()\n",
    "\n",
    "# UDF to apply the conversion function\n",
    "sparse_to_dense_udf = udf(sparse_to_dense, ArrayType(FloatType()))\n",
    "\n",
    "# Apply the UDF and add as a new column 'tfidf_dense'\n",
    "df_words_dense = df_words_norm.withColumn('tfidf_dense', sparse_to_dense_udf(df_words_norm['normFeatures']))\n",
    "df_words_dense.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "177395cd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-06T15:34:21.081286Z",
     "iopub.status.busy": "2023-10-06T15:34:21.080893Z",
     "iopub.status.idle": "2023-10-06T15:34:21.472552Z",
     "shell.execute_reply": "2023-10-06T15:34:21.471480Z"
    },
    "papermill": {
     "duration": 0.407996,
     "end_time": "2023-10-06T15:34:21.475582",
     "exception": false,
     "start_time": "2023-10-06T15:34:21.067586",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----------+\n",
      "|            sentence| word_array|\n",
      "+--------------------+-----------+\n",
      "|This is the first...|     [This]|\n",
      "|This is the first...|       [is]|\n",
      "|This is the first...|      [the]|\n",
      "|This is the first...|    [first]|\n",
      "|This is the first...|[sentence.]|\n",
      "|Here is the secon...|     [Here]|\n",
      "|Here is the secon...|       [is]|\n",
      "|Here is the secon...|      [the]|\n",
      "|Here is the secon...|   [second]|\n",
      "|Here is the secon...|[sentence.]|\n",
      "|And here's a thir...|      [And]|\n",
      "|And here's a thir...|   [here's]|\n",
      "|And here's a thir...|        [a]|\n",
      "|And here's a thir...|    [third]|\n",
      "|And here's a thir...|[sentence.]|\n",
      "+--------------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_words = df_words.drop(\"rawFeatures\",\"features\")\n",
    "df_words.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d59f0cce",
   "metadata": {
    "papermill": {
     "duration": 0.020481,
     "end_time": "2023-10-06T15:34:21.516560",
     "exception": false,
     "start_time": "2023-10-06T15:34:21.496079",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9e146357",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-06T15:34:21.552582Z",
     "iopub.status.busy": "2023-10-06T15:34:21.552231Z",
     "iopub.status.idle": "2023-10-06T15:34:22.039478Z",
     "shell.execute_reply": "2023-10-06T15:34:22.038472Z"
    },
    "papermill": {
     "duration": 0.505074,
     "end_time": "2023-10-06T15:34:22.042593",
     "exception": false,
     "start_time": "2023-10-06T15:34:21.537519",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+-----+\n",
      "|            features|           features2|label|\n",
      "+--------------------+--------------------+-----+\n",
      "|[1.0, 1.0, 1.0, 1.0]|[1.0, 1.0, 1.0, 1.0]|  1.0|\n",
      "|[2.0, 2.0, 2.0, 2.0]|[1.0, 1.0, 1.0, 1.0]|  1.0|\n",
      "|[3.0, 3.0, 3.0, 3.0]|[1.0, 1.0, 1.0, 1.0]|  1.0|\n",
      "+--------------------+--------------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Sample data\n",
    "data = [([1.0, 1.0, 1.0, 1.0], [1.0, 1.0, 1.0, 1.0],1.0), \n",
    "        ([2.0, 2.0, 2.0, 2.0],[1.0, 1.0, 1.0, 1.0], 1.0), \n",
    "        ([3.0, 3.0, 3.0, 3.0],[1.0, 1.0, 1.0, 1.0], 1.0)]\n",
    "\n",
    "# Define the schema for the DataFrame\n",
    "schema = StructType([\n",
    "    StructField(\"features\", ArrayType(DoubleType()), True),\n",
    "    StructField(\"features2\", ArrayType(DoubleType()), True),\n",
    "    StructField(\"label\", DoubleType(), True)\n",
    "])\n",
    "\n",
    "# Create a DataFrame\n",
    "df = spark.createDataFrame(data, schema=schema)\n",
    "# Show the DataFrame\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d47d6abf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-06T15:34:22.096213Z",
     "iopub.status.busy": "2023-10-06T15:34:22.095738Z",
     "iopub.status.idle": "2023-10-06T15:34:22.782682Z",
     "shell.execute_reply": "2023-10-06T15:34:22.780975Z"
    },
    "papermill": {
     "duration": 0.717918,
     "end_time": "2023-10-06T15:34:22.785608",
     "exception": false,
     "start_time": "2023-10-06T15:34:22.067690",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+-----+--------------------+\n",
      "|            features|           features2|label|         dot_product|\n",
      "+--------------------+--------------------+-----+--------------------+\n",
      "|[1.0, 1.0, 1.0, 1.0]|[1.0, 1.0, 1.0, 1.0]|  1.0|[1.0, 1.0, 1.0, 1.0]|\n",
      "|[2.0, 2.0, 2.0, 2.0]|[1.0, 1.0, 1.0, 1.0]|  1.0|[2.0, 2.0, 2.0, 2.0]|\n",
      "|[3.0, 3.0, 3.0, 3.0]|[1.0, 1.0, 1.0, 1.0]|  1.0|[3.0, 3.0, 3.0, 3.0]|\n",
      "+--------------------+--------------------+-----+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_dot_product = df.withColumn(\"dot_product\",\n",
    "                               F.expr(\"transform(features, (x, i) -> x * features2[i])\"))\n",
    "df_dot_product.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9e3e92dc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-06T15:34:22.828966Z",
     "iopub.status.busy": "2023-10-06T15:34:22.828520Z",
     "iopub.status.idle": "2023-10-06T15:34:23.397894Z",
     "shell.execute_reply": "2023-10-06T15:34:23.396629Z"
    },
    "papermill": {
     "duration": 0.59565,
     "end_time": "2023-10-06T15:34:23.401860",
     "exception": false,
     "start_time": "2023-10-06T15:34:22.806210",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+-----+--------------------+---------------+\n",
      "|            features|           features2|label|         dot_product|dot_product_sum|\n",
      "+--------------------+--------------------+-----+--------------------+---------------+\n",
      "|[1.0, 1.0, 1.0, 1.0]|[1.0, 1.0, 1.0, 1.0]|  1.0|[1.0, 1.0, 1.0, 1.0]|            4.0|\n",
      "|[2.0, 2.0, 2.0, 2.0]|[1.0, 1.0, 1.0, 1.0]|  1.0|[2.0, 2.0, 2.0, 2.0]|            8.0|\n",
      "|[3.0, 3.0, 3.0, 3.0]|[1.0, 1.0, 1.0, 1.0]|  1.0|[3.0, 3.0, 3.0, 3.0]|           12.0|\n",
      "+--------------------+--------------------+-----+--------------------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Calculate the sum of the array elements and create a new column\n",
    "df_dot_product = df_dot_product.withColumn(\"dot_product_sum\",\n",
    "                                           F.expr('aggregate(dot_product, 0D, (acc, x) -> acc + x)'))\n",
    "df_dot_product.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "655736c9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-06T15:34:23.453750Z",
     "iopub.status.busy": "2023-10-06T15:34:23.453270Z",
     "iopub.status.idle": "2023-10-06T15:34:24.010180Z",
     "shell.execute_reply": "2023-10-06T15:34:24.008889Z"
    },
    "papermill": {
     "duration": 0.583755,
     "end_time": "2023-10-06T15:34:24.013271",
     "exception": false,
     "start_time": "2023-10-06T15:34:23.429516",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+-----+--------------------+---------------+--------------------+--------------------+\n",
      "|            features|           features2|label|         dot_product|dot_product_sum|            mag_list|           mag_list2|\n",
      "+--------------------+--------------------+-----+--------------------+---------------+--------------------+--------------------+\n",
      "|[1.0, 1.0, 1.0, 1.0]|[1.0, 1.0, 1.0, 1.0]|  1.0|[1.0, 1.0, 1.0, 1.0]|            4.0|[1.0, 1.0, 1.0, 1.0]|[1.0, 1.0, 1.0, 1.0]|\n",
      "|[2.0, 2.0, 2.0, 2.0]|[1.0, 1.0, 1.0, 1.0]|  1.0|[2.0, 2.0, 2.0, 2.0]|            8.0|[4.0, 4.0, 4.0, 4.0]|[1.0, 1.0, 1.0, 1.0]|\n",
      "|[3.0, 3.0, 3.0, 3.0]|[1.0, 1.0, 1.0, 1.0]|  1.0|[3.0, 3.0, 3.0, 3.0]|           12.0|[9.0, 9.0, 9.0, 9.0]|[1.0, 1.0, 1.0, 1.0]|\n",
      "+--------------------+--------------------+-----+--------------------+---------------+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Calculate the magnitude of each vector\n",
    "df_dot_product = df_dot_product.withColumn(\"mag_list\", \n",
    "                    F.expr(\"transform(features, x -> x * x)\"))\n",
    "# Calculate the magnitude of each vector\n",
    "df_dot_product = df_dot_product.withColumn(\"mag_list2\", \n",
    "                    F.expr(\"transform(features2, x -> x * x)\"))\n",
    "df_dot_product.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d7800baf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-06T15:34:24.057415Z",
     "iopub.status.busy": "2023-10-06T15:34:24.056870Z",
     "iopub.status.idle": "2023-10-06T15:34:25.006175Z",
     "shell.execute_reply": "2023-10-06T15:34:25.005051Z"
    },
    "papermill": {
     "duration": 0.978176,
     "end_time": "2023-10-06T15:34:25.012573",
     "exception": false,
     "start_time": "2023-10-06T15:34:24.034397",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+---------------+--------------------+--------------------+------------+-------------+\n",
      "|            features|           features2|         dot_product|dot_product_sum|            mag_list|           mag_list2|mag_list_sum|mag_list_sum2|\n",
      "+--------------------+--------------------+--------------------+---------------+--------------------+--------------------+------------+-------------+\n",
      "|[1.0, 1.0, 1.0, 1.0]|[1.0, 1.0, 1.0, 1.0]|[1.0, 1.0, 1.0, 1.0]|            4.0|[1.0, 1.0, 1.0, 1.0]|[1.0, 1.0, 1.0, 1.0]|         2.0|          2.0|\n",
      "|[2.0, 2.0, 2.0, 2.0]|[1.0, 1.0, 1.0, 1.0]|[2.0, 2.0, 2.0, 2.0]|            8.0|[4.0, 4.0, 4.0, 4.0]|[1.0, 1.0, 1.0, 1.0]|         4.0|          2.0|\n",
      "|[3.0, 3.0, 3.0, 3.0]|[1.0, 1.0, 1.0, 1.0]|[3.0, 3.0, 3.0, 3.0]|           12.0|[9.0, 9.0, 9.0, 9.0]|[1.0, 1.0, 1.0, 1.0]|         6.0|          2.0|\n",
      "+--------------------+--------------------+--------------------+---------------+--------------------+--------------------+------------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_dot_product = df_dot_product.drop('label') \n",
    "df_dot_product = df_dot_product.drop('label') \n",
    "df_dot_product = df_dot_product.withColumn(\"mag_list_sum\",\n",
    "                    F.sqrt(F.expr('aggregate(mag_list, 0D, (acc, x) -> acc + x)')))\n",
    "df_dot_product = df_dot_product.withColumn(\"mag_list_sum2\",\n",
    "                    F.sqrt(F.expr('aggregate(mag_list2, 0D, (acc, x) -> acc + x)')))\n",
    "df_dot_product.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0750265",
   "metadata": {
    "papermill": {
     "duration": 0.020418,
     "end_time": "2023-10-06T15:34:25.054914",
     "exception": false,
     "start_time": "2023-10-06T15:34:25.034496",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9ab64bd4",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-10-06T15:34:25.100122Z",
     "iopub.status.busy": "2023-10-06T15:34:25.099659Z",
     "iopub.status.idle": "2023-10-06T15:34:25.107456Z",
     "shell.execute_reply": "2023-10-06T15:34:25.106367Z"
    },
    "papermill": {
     "duration": 0.036002,
     "end_time": "2023-10-06T15:34:25.112120",
     "exception": false,
     "start_time": "2023-10-06T15:34:25.076118",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 83.256571,
   "end_time": "2023-10-06T15:34:27.755378",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-10-06T15:33:04.498807",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
